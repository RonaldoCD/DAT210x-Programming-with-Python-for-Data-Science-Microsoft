{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAT210x - Programming with Python for DS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module5- Lab7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Leave this alone until indicated:\n",
    "Test_PCA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Convenience Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is for your visualization convenience only. You aren't expected to know how to put this together yourself, although you should be able to follow the code by now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotDecisionBoundary(model, X, y):\n",
    "    print(\"Plotting...\")\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    padding = 0.1\n",
    "    resolution = 0.1\n",
    "\n",
    "    #(2 for benign, 4 for malignant)\n",
    "    colors = {2:'royalblue', 4:'lightsalmon'} \n",
    "\n",
    "\n",
    "    # Calculate the boundaris\n",
    "    x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "    y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "    x_range = x_max - x_min\n",
    "    y_range = y_max - y_min\n",
    "    x_min -= x_range * padding\n",
    "    y_min -= y_range * padding\n",
    "    x_max += x_range * padding\n",
    "    y_max += y_range * padding\n",
    "\n",
    "    # Create a 2D Grid Matrix. The values stored in the matrix\n",
    "    # are the predictions of the class at at said location\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, resolution),\n",
    "                         np.arange(y_min, y_max, resolution))\n",
    "\n",
    "    # What class does the classifier say?\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # Plot the contour map\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.seismic)\n",
    "    plt.axis('tight')\n",
    "\n",
    "    # Plot your testing points as well...\n",
    "    for label in np.unique(y):\n",
    "        indices = np.where(y == label)\n",
    "        plt.scatter(X[indices, 0], X[indices, 1], c=colors[label], alpha=0.8)\n",
    "\n",
    "    p = model.get_params()\n",
    "    plt.title('K = ' + str(p['n_neighbors']))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### The Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load in the dataset, identify nans, and set proper headers. Be sure to verify the rows line up by looking at the file in a text editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thickness</th>\n",
       "      <th>size</th>\n",
       "      <th>shape</th>\n",
       "      <th>adhesion</th>\n",
       "      <th>epithelial</th>\n",
       "      <th>nuclei</th>\n",
       "      <th>chromatin</th>\n",
       "      <th>nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000025</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002945</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015425</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016277</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017023</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776715</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841769</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888820</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897471</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897471</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         thickness  size  shape  adhesion  epithelial nuclei  chromatin  \\\n",
       "sample                                                                    \n",
       "1000025          5     1      1         1           2      1          3   \n",
       "1002945          5     4      4         5           7     10          3   \n",
       "1015425          3     1      1         1           2      2          3   \n",
       "1016277          6     8      8         1           3      4          3   \n",
       "1017023          4     1      1         3           2      1          3   \n",
       "...            ...   ...    ...       ...         ...    ...        ...   \n",
       "776715           3     1      1         1           3      2          1   \n",
       "841769           2     1      1         1           2      1          1   \n",
       "888820           5    10     10         3           7      3          8   \n",
       "897471           4     8      6         4           3      4         10   \n",
       "897471           4     8      8         5           4      5         10   \n",
       "\n",
       "         nucleoli  mitoses  status  \n",
       "sample                              \n",
       "1000025         1        1       2  \n",
       "1002945         2        1       2  \n",
       "1015425         1        1       2  \n",
       "1016277         7        1       2  \n",
       "1017023         1        1       2  \n",
       "...           ...      ...     ...  \n",
       "776715          1        1       2  \n",
       "841769          1        1       2  \n",
       "888820         10        2       4  \n",
       "897471          6        1       4  \n",
       "897471          4        1       4  \n",
       "\n",
       "[699 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .. your code here ..\n",
    "columns = ['sample', 'thickness', 'size', 'shape', 'adhesion', 'epithelial', 'nuclei', 'chromatin', 'nucleoli', 'mitoses', 'status']\n",
    "df = pd.read_csv('Datasets/breast-cancer-wisconsin.data', names = columns, index_col = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thickness</th>\n",
       "      <th>size</th>\n",
       "      <th>shape</th>\n",
       "      <th>adhesion</th>\n",
       "      <th>epithelial</th>\n",
       "      <th>nuclei</th>\n",
       "      <th>chromatin</th>\n",
       "      <th>nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000025</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002945</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015425</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016277</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017023</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776715</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841769</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888820</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897471</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897471</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         thickness  size  shape  adhesion  epithelial nuclei  chromatin  \\\n",
       "sample                                                                    \n",
       "1000025          5     1      1         1           2      1          3   \n",
       "1002945          5     4      4         5           7     10          3   \n",
       "1015425          3     1      1         1           2      2          3   \n",
       "1016277          6     8      8         1           3      4          3   \n",
       "1017023          4     1      1         3           2      1          3   \n",
       "...            ...   ...    ...       ...         ...    ...        ...   \n",
       "776715           3     1      1         1           3      2          1   \n",
       "841769           2     1      1         1           2      1          1   \n",
       "888820           5    10     10         3           7      3          8   \n",
       "897471           4     8      6         4           3      4         10   \n",
       "897471           4     8      8         5           4      5         10   \n",
       "\n",
       "         nucleoli  mitoses  status  \n",
       "sample                              \n",
       "1000025         1        1       2  \n",
       "1002945         2        1       2  \n",
       "1015425         1        1       2  \n",
       "1016277         7        1       2  \n",
       "1017023         1        1       2  \n",
       "...           ...      ...     ...  \n",
       "776715          1        1       2  \n",
       "841769          1        1       2  \n",
       "888820         10        2       4  \n",
       "897471          6        1       4  \n",
       "897471          4        1       4  \n",
       "\n",
       "[699 rows x 10 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis = 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy out the status column into a slice, then drop it from the main dataframe. Always verify you properly executed the drop by double checking (printing out the resulting operating)! Many people forget to set the right axis here.\n",
    "\n",
    "If you goofed up on loading the dataset and notice you have a `sample` column, this would be a good place to drop that too if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. your code here ..\n",
    "labels = df.loc[:,'status']\n",
    "df = df.drop('status', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the labels safely extracted from the dataset, replace any nan values with the mean feature / column value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. your code here ..\n",
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "thickness       int64\n",
       "size            int64\n",
       "shape           int64\n",
       "adhesion        int64\n",
       "epithelial      int64\n",
       "nuclei        float64\n",
       "chromatin       int64\n",
       "nucleoli        int64\n",
       "mitoses         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nuclei = pd.to_numeric(df.nuclei, errors ='coerce') \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thickness</th>\n",
       "      <th>size</th>\n",
       "      <th>shape</th>\n",
       "      <th>adhesion</th>\n",
       "      <th>epithelial</th>\n",
       "      <th>nuclei</th>\n",
       "      <th>chromatin</th>\n",
       "      <th>nucleoli</th>\n",
       "      <th>mitoses</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000025</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002945</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015425</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016277</th>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017023</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776715</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841769</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888820</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897471</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897471</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         thickness  size  shape  adhesion  epithelial  nuclei  chromatin  \\\n",
       "sample                                                                     \n",
       "1000025          5     1      1         1           2     1.0          3   \n",
       "1002945          5     4      4         5           7    10.0          3   \n",
       "1015425          3     1      1         1           2     2.0          3   \n",
       "1016277          6     8      8         1           3     4.0          3   \n",
       "1017023          4     1      1         3           2     1.0          3   \n",
       "...            ...   ...    ...       ...         ...     ...        ...   \n",
       "776715           3     1      1         1           3     2.0          1   \n",
       "841769           2     1      1         1           2     1.0          1   \n",
       "888820           5    10     10         3           7     3.0          8   \n",
       "897471           4     8      6         4           3     4.0         10   \n",
       "897471           4     8      8         5           4     5.0         10   \n",
       "\n",
       "         nucleoli  mitoses  \n",
       "sample                      \n",
       "1000025         1        1  \n",
       "1002945         2        1  \n",
       "1015425         1        1  \n",
       "1016277         7        1  \n",
       "1017023         1        1  \n",
       "...           ...      ...  \n",
       "776715          1        1  \n",
       "841769          1        1  \n",
       "888820         10        2  \n",
       "897471          6        1  \n",
       "897471          4        1  \n",
       "\n",
       "[699 rows x 9 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do train_test_split. Use the same variable names as on the EdX platform in the reading material, but set the random_state=7 for reproducibility, and keep the test_size at 0.5 (50%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .. your code here ..\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df, labels, test_size=0.5, random_state=7, stratify=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the basic SKLearn preprocessing scalers. We know that the features consist of different units mixed in together, so it might be reasonable to assume feature scaling is necessary. Print out a description of the dataset, post transformation. Recall: when you do pre-processing, which portion of the dataset is your model trained upon? Also which portion(s) of your dataset actually get transformed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-d78faccaa040>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train_minmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_max_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_minmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_minmax\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "# .. your code here ..\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "\n",
    "X_train = X_train_minmax.transform(X_train)\n",
    "X_test = X_train_minmax.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "normalizer = Normalizer().fit(X_train)\n",
    "X_train = normalizer.transform(X_train)\n",
    "X_test = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA and Isomap are your new best friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing 2D Isomap Manifold\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "\n",
    "if Test_PCA:\n",
    "    print('Computing 2D Principle Components')\n",
    "    # TODO: Implement PCA here. Save your model into the variable 'model'.\n",
    "    # You should reduce down to two dimensions.\n",
    "    \n",
    "    # .. your code here ..\n",
    "    from sklearn.decomposition import PCA\n",
    "    model = PCA(n_components = 2, svd_solver = 'full')\n",
    "    model.fit(X_train)\n",
    "    data_train = model.transform(X_train)\n",
    "    data_test = model.transform(X_test)\n",
    "\n",
    "else:\n",
    "    print('Computing 2D Isomap Manifold')\n",
    "    # TODO: Implement Isomap here. Save your model into the variable 'model'\n",
    "    # Experiment with K values from 5-10.\n",
    "    # You should reduce down to two dimensions.\n",
    "\n",
    "    # .. your code here ..\n",
    "    from sklearn import manifold\n",
    "    model = manifold.Isomap(n_neighbors = 5, n_components = 2)\n",
    "    model.fit(X_train)\n",
    "    data_train = model.transform(X_train)\n",
    "    data_test = model.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your model against data_train, then transform both `data_train` and `data_test` using your model. You can save the results right back into the variables themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# .. your code here .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement and train `KNeighborsClassifier` on your projected 2D training data here. You can name your variable `knmodel`. You can use any `K` value from 1 - 15, so play around with it and see what results you can come up. Your goal is to find a good balance where you aren't too specific (low-K), nor are you too general (high-K). You should also experiment with how changing the weights parameter affects the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .. your code here ..\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(data_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to always keep the domain of the problem in mind! It's WAY more important to errantly classify a benign tumor as malignant, and have it removed, than to incorrectly leave a malignant tumor, believing it to be benign, and then having the patient progress in cancer. Since the UDF weights don't give you any class information, the only way to introduce this data into SKLearn's KNN Classifier is by \"baking\" it into your data. For example, randomly reducing the ratio of benign samples compared to malignant samples from the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Calculate and display the accuracy of the testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96857142857142853"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .. your code changes above ..\n",
    "knn.predict(data_test)\n",
    "knn.score(data_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting...\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEJCAYAAAB8Pye7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xt4VNW5+PHvZJKQG4RkAgTCpYAFBIoKERBNSEjwULSK1KpQuXg5FDlVkSMKijKtgvzooSoVFCqCoHhr1d4sQkgCWAWhgBTQcBEBkVtIQsiNTDL798eQSSYzk0wys/eeZL+f5+GBWbMz75oxvmvP2muv16QoioIQQghDCdG7A0IIIbQnyV8IIQxIkr8QQhiQJH8hhDAgSf5CCGFAkvyFEMKAJPkLIYQBSfIXrdLUqVPJzMx0adu9ezeJiYnccccdlJeXqxZ7wYIFpKSk0K5dO0wmE99//73H4xYvXkyPHj2IiIjguuuuY+PGjar1SYj6JPkLQ9i4cSMjR45k/Pjx/PnPfyYyMlK1WJcvX+a2227j6aef9nrMSy+9xPz583nuuefYs2cPo0eP5mc/+xn79u1TrV9C1GWSO3xFazR16lS+//57srKyWLduHQ8++CDPPPMM8+bN06wPubm5pKenc/LkSbp27epsVxSFrl27MmXKFBYuXOhsv/766xkwYABr1qzRrI/CuOTMX7Rqixcv5oEHHmDFihU+Jf6FCxcSExPT4J+6Cbs5vvvuO3744QfGjBnj0j5mzBg+++wzv15bCF+F6t0BIdSybds2Nm/ezNq1a5k0aZJPPzN9+nTuuuuuBo+Jj4/3q1+nT58GIDEx0aU9MTHR+ZwQapPkL1qtfv36YbPZeOGFF8jIyKBLly6N/kx8fLzfyd0fJpNJt9jCWGTaR7RaHTp0YOvWrURERJCamsrx48cb/Rktpn06d+4MwJkzZ1zaz5496/ZtQAi1yJm/aNUSEhLIzs7mpz/9KSkpKWzevJkf//jHXo/XYtrnRz/6EV26dOHTTz8lNTXV2b5hwwZuuukmv15bCF9J8hetXvv27dm0aRO33XYbqampZGVlMWDAAI/HBmLa58SJExQUFHDkyBEADh48SH5+Pt27dyc+Ph6TycTs2bN56qmnuPrqq0lOTmbNmjV89dVX/PGPf/QrthC+kuQvDCEmJoZPPvmEn//856SlpfHpp58yePBgVWI9++yzvPnmm87H//Vf/wXA6tWrmTp1KgAzZ86ksrKSp556irNnz3L11Vfz17/+lWuuuUaVPglRn6zzF0IIA5ILvkIIYUB+T/vk5+ezbNkyioqKMJlMZGZmMnbsWJdjDhw4wOLFi+nYsSMAw4YN48477/Q3tBBCiGbyO/mbzWYmTZpEr169KC8vZ86cOQwaNMjldnaAq6++mjlz5vgbTgghRAD4Pe0TFxdHr169AIiMjCQpKYmCggK/OyaEEEI9AV3tc+7cOY4dO8ZVV13l9tyhQ4eYPXs2cXFxTJo0iW7durkdk5WVRVZWFgCLFi0KZNeEEELUEbDVPhUVFcyfP5/x48czbNgwl+fKysoICQkhIiKC3bt3s2bNGpYuXdp450xPBaJrQghNTSQ9fSBWK6RWZYPVyrFt2wDI1bVfxnCfjyk9IKt9qqqqWLJkCSkpKW6JHyAqKoqIiAgABg8eTHV1NcXFxYEILYQQohn8Tv6KovDaa6+RlJTErbfe6vGYoqIiar5gHDlyBLvdTtu2bf0NLYQQopn8nvPPy8tj69atdO/endmzZwMwYcIE8vPzAbj55pvZvn07GzduxGw2Ex4ezsyZM2X3QiGE0JHfyb9fv368//77DR4zZswYt8IVQggh9CN3+AohhAFJ8hdCCAOS5C+EEAYkyV8IIQxIkr8QQhiQJH8hhDAgSf5CCGFAkvyFEKqwWmFr6CiwWumZkqJ3d0Q9QV3GUTZ2U9e1PeDVydAhBs6XwENrYe9x7eJ3bg+Pjnb8fboIXt7k+FsLC8fDE7eCCVCAxX+Hpz7UJjbAPcNg5VRoEwaXbTBtDby7Q7v42nDf4K2oXzva3fAT5xHFX/yHwj/+w+0nc1XqUVyPDoyYPJaImCgqSsr4fO0nFB4/r1I0V+mP/pzu1/zY+fjEV4fJefnPAY/j68ZukvwN6toekP0EhNe5x7uyCkYt1mYA6Nwe3v4VtIsERQGTCYrL4Zcr1B8AFo6HOT9zb1/0N20GgHuGOd573R1OFMXx3lv1APDdYlAuOt5sXYdOw2dHXZrU2AU0rkcHfvrEJEJCayc87FV2/rl4neoDQPqjP6fHtX3c2o/vPRTwAUDTXT1Fy/PqZNfED47Hr07WJv6jo2sTPzj+bhfpaFfbE573H/TaHmgrp7omfnA8XjlVm/jaWk9OzlOMHLkfe/VFFEAxmVz+2Pt2YevzW13+9Ny8mZ4pKaQFsCcjJo91SfwAIaEhjJg81stPBE7dM35f2rUQ0GIuouXoEOO5PcFLe6B1bu9+AqgokBirfmxvWwpqtdVgm7CmtbcO6wGTY46tPsVxfaAuq3UUqVboabXCtm0B+QYQERPlpT0yAK/e8kjyN6jzJZDY3r09v0Sb+KeLYECS6wBgMsGZi+rHVvCc6LWa/7xsgzCz5/bWzdsnDzk5++u1DMRqHQXPjyK1KpueVwrC5PoRvaKkjMj20R7ay/141ZZLpn0M6qG1jjn+uiqrHO1aeHmTY46/ZvqjZs7/5U3qx17896a1B9q0NZ6/9Uxbo018vbzzBTgGANc/73yh4PhmUPunZqqo/oqhND/if772E+xVdpc2e5Wdz9d+4ser+ubEV4eb1K4FueBrYDWrfRJiHGf8eq32SYx1nPHLah/t4uvlrf+GCTfUPn7nC7j3jw39hPuKIai9INxUYT06kDB5LCExkdhLytkgq32CkyR/IQRMBPA4CASCv9NJwSQN6OljSpc5fyFEkFsPQE7ORGquBaRaA/fqgbyorJe0K3835WY6OfMXQrQgjmmgQKn7TUKNewu0kMaVpG+1sjV0FKmpvv2cJH8hRAs0MSCvUjOQ1B8EcgPy6upLwzXxW62Qne3bz0ryF0IYnPtF5WAfANKoTfqAM/Hn5OxHUXz7ZiRz/kIIg1vvcj2h/r0FvshVtX8Nq0n8TSXJXwghWE9OjuOisuNbQJ07jH0R5N8UPPE7+efn57Ns2TKKioowmUxkZmYydqzrXhmKorB69Wr27NlDmzZtmDFjBr169fI3tBBCBNj6Zq0qaokrhvxO/mazmUmTJtGrVy/Ky8uZM2cOgwYNomvXrs5j9uzZw5kzZ1i6dCmHDx/m9ddfZ+HChf6GFkIIFTgGgJwcSE/3cUolgNtQaMXv5B8XF0dcXBwAkZGRJCUlUVBQ4JL8d+3aRWpqKiaTiT59+lBaWkphYaHz54QQIrjU3luQk9P40W5TRS1gAAjonP+5c+c4duwYV111lUt7QUEBCQkJzscWi4WCggK35J+VlUVWVhYAixYtCmTXhBCiGdb7dFT9qaKeEPTfAgKW/CsqKliyZAlTp04lKsp161RPq0lN9Tc0BzIzM8nMzAxUl4QQQiP1rhVU+bjYvhnScF3bX8OxM+p6wLcp9YAk/6qqKpYsWUJKSgrDhg1ze95isZCfn+98fOHCBZnyEUKIJkrD/aau2qTfNH4nf0VReO2110hKSuLWWz2XQkpOTmbDhg3ceOONHD58mKioKEn+QgjN6Vk32h9peL+pqzmJHwKQ/PPy8ti6dSvdu3dn9uzZAEyYMMF5pn/zzTdz3XXXsXv3bh555BHCw8OZMWOGv2GFEKJJ6teNHpAEQ3tpUzfaH2kE7my/Lr+Tf79+/Xj//fcbPMZkMvHggw/6G0oIIZqtobrRcz7Qt2+epF35W43ED3KHrxDCIPSsG91UabgnfQhc4gcp4yiEMIjTRbVlQ2uoVTfan9KTabjO79cIZOIHSf5CCINQv260OrWH1SLJXwhhCKeLHBd3sw7AgVOOv9W52LuenBz3AeC+IBsEZM5fCGEYp4u0urhbb3+gOnv/BMvWD3LmL4QQqliPt28BaaD7twA58xdCCFXVbv0Atd8C0PlbgCR/IYRQ3foru4PW2wCukQHAdW1/YEkNXyGE0FS9msHgrBsM/t/UpSi+bewmyV8IIXThXjg+EDd1SfIXQoigVzsA1PB3CwdJ/kII0SJMBBzVwMD/O3l9Tf5ywVcIIXRVWzIykNs3NEbW+QshRFDQLvGDJH8hhDAkSf5CCGFAkvyFEMKA5IKv0I2e9VT1ruWqZ/xre8Crk6FDDJwvgYfWwt7j2sS+ZxisnAptwuCyDaatgXd3aBNbuJKlnkIX9eup1uytrkU9VT1j6x3/2h6Q/QSE1zntq6yCUYvVHwDuGeZ433ULqiiK433LABA4vi71lGkfoYuG6qm25th6x391smviB8fjVyerH3vlVM+VtFZOVT+2cCfJX+hCz3qqetdy1TN+hxjP7Qle2gOpTVjT2oW6JPkLXWhZTzWYYusd/3yJ5/Z8L+2BdNnWtHahroAk/+XLl/Pggw/yv//7vx6fP3DgAFOmTGH27NnMnj2bP/3pT4EIK1ow9eupBmdsveM/tNYxx19XZZWjXW3T1nj+xjNtjfqxhbuAXPA9ePAgERERLFu2jCVLlrg9f+DAAf72t78xZ86cpnVOLvi2ajUrXhJjHWe9eqz20SO23vFrVvskxDjO+GW1T+ui6d4+/fv359y5c4F4KWEg2tVTDa7YesffexxueE6f2O/ukGQfLDRb53/o0CFmz55NXFwckyZNolu3bm7HZGVlkZWVBcCiRYu06poQQhiOJsm/Z8+eLF++nIiICHbv3s3vfvc7li5d6nZcZmYmmZmZWnRJCNGqTdS7A15ou3lbQzRJ/lFRUc5/Dx48mFWrVlFcXEy7du20CC+EMBT3AinBwNGfhX7v1x8omiT/oqIiYmNjMZlMHDlyBLvdTtu2bbUILYQwjInOgigu9XGDRPY8R0F2GKj53v2eBCT5v/TSSxw8eJBLly4xffp07rrrLqqqHOvJbr75ZrZv387GjRsxm82Eh4czc+ZMTPUXOgshRLPVq4c7z6p3hzxKtYLVWncAAL0GAdnbRwjRgtWWQKxbCP3Ytm3k6tovd2lAz5QUx4M6hdoDPQ0kNXyFEK3cRLekDwRl4q+RhvoDgNTwFUK0UL6t1GkJZ/teqXjm7ytJ/kKIIFF7wbYxNSt5WkriT7vyd8+UlKBI/CDJXwgRFOpN4TSmihaR9KHOVE+dpA/6Jn6Q5C+E0J3nufvGtNTEr3fSryHJXwihk3pJv87ZvC9y1eyan9KoTfpA0CV+kOQvhNCF+9l+SziT90UawXu2X5ckf50ZuYi5noz83vU0eiCsfgDaRrxPpf1vnLp0B0RqFz+yfTT9Rw8lqn0MZUUlHNz0JeVFpQF7/TS8J/5g+52T5K+j+oW8ByTB0F76FDHXMrbejPze9TR6IPzjMQgxAVQTQwnx+W9B/E80iR/ZPpqRvxpHWGQ4KNA+KYEOvbqwZcXHAR0APAnG3zkp46gjIxcx15OR37ueVj9Qk/hrmDChQOHXmsTvP3qoM/EDoEBYZDj9Rw9VPXYw/s5J8teRkYuY68nI711PbSM8tZpAqdYkflT7mNrEX0OBqNho1WMH4++cJH8dGbmIuZ6M/N71dKnCU6sCJrMm8cuKSqD+fpImKLuo7pQPBOfvnCR/HRm5iLmejPze9XTfKrC7nP0qKJgg7mpN4h/c9CW28sraAcAEtvJKDm76UvXYwfg7Jxd8dXS6yHHBR49C3nrG1puR37ueNu2HW16sWe1jptIeyaked3BN5A+axC8vKmXLio8dq31ioym7WBrw1T7eBOPvnOzqKYTQQeta559G8NzUJbt6CiGEBtJoGTd11SfJXwghmiHtyt8tMfGDJH8hhGiyNIJzp86mkOQvhBBNkEbLPduvS5K/EEL4IA3XpA+02MQPss5fCCGapSUnfpDkL4QQhhSQaZ/ly5eze/duYmNjWbJkidvziqKwevVq9uzZQ5s2bZgxYwa9evUKRGghhBDNEJAz/7S0NJ56yvsNWXv27OHMmTMsXbqUadOm8frrrwcirBBCiGYKSPLv378/MTExXp/ftWsXqampmEwm+vTpQ2lpKYWFhYEILYQQohk0We1TUFBAQkKC87HFYqGgoIC4uDiX47KyssjKygJg0aJFWnRNCKG52q0dhH40Sf6etg8y1d/fFMjMzCQzM1OLLgnRSky88ndLWXHSuvb0ack0Sf4Wi4X8/Hzn4wsXLrid9esp2GpritavR+cI5t4VR2I7hTPFJl54v5Djpz1ueO+FI4mCY8mh1brQ52WH9wyDlVOhTRhctsG0NfDujma8iSZx9NcSeZHf//cGup09DF/s5MR/dmua+NWu4duQa3vAq5OhQwycL4GH1sLe45qE9kiT5J+cnMyGDRu48cYbOXz4MFFRUUGT/IOxtqZo3Xp0juBPs6KJDitHwUQfi8KQWdHc+Xt8HADqnT1XgdU6ChhITs5EGhoA7hnm+H2v+eIdZnY8BjUHAEd/Fz59keHnVsKRk1wuKYHYUMJ+NY5IDWrogr41fK/tAdlPQPiVjJvY3vF41GL9BoCAXPB96aWXmDdvHj/88APTp08nOzubjRs3snHjRgCuu+46OnbsyCOPPMKKFSt48MEHAxE2IIKxtqZo3ebeFUd0WLWjkAmgYCI6rJq5dzV2QjQRT9MmWK2kVmVjtUJ6+kDS0xdSOx3kauVUzxWlVk715x013Oea/g6/+C6cciT+S8AlDWvogr41fF+dXJv4a4SHOtr1EpAz/5kzZzb4vMlkCqqEX1cw1tYUrVtiO8WZ+GsomOjUrqHSGvWS/jwrAMe2bXM8nZFBakoK2c6tBzx/C2gT5vnVvbU3n/u3E3bv5HKonUt1D9Oohi7oW8O3g5fFkAneF0mqzvB3+AZjbU3Rup0pNmGql4VMKJwtdl8E4eD5IunqKxdKa/4c27bN7VtA/W8Al22eI3hrbx4P/c3IYN+hb7mkUw1d0LeG7/kSz+35Xtq1YPiN3V7e5Jjjr5n6CYbamqJ1e+H9QobMiiM6zIaCYyAotYXxwvvDgUiXY+suiQzE6phpa1zn/MHxez9tTTNf0MXEBvsbuelLOvTqUjv1omENXXDU8NUr/kNrXef8ASqrHO16MXzyD8bamqJ1O356PP9va2fGX7uN+IgSCipi+HBvCr36WejVz/XYQC+JrLmoG/jVPo0v4dSzhq7e8fced1zcfXWyY6on3yirfYLd6SKY84HevRDG4EiSDz8OqVXtgHYATEj7yvPhVQR8Lfy7OwK5sscxreTr2v3yolL+/UFOoII3mZ7x9x6HG57TJbRHkvyF0ISHC6A+3OJac0E3V82uNZv3i9C5enZL+ESSvxCq8zwl4otcVfvlD7lTt6WT5C+Ealzvwm0dSdLzN5iW/Z6MSZK/EE3m+Qaq+upPiag9hZMLsG0bPa1WUq21d/2C71s/NEzO9lsTSf5CNEnt2Xxj9EiSuQDbtvl805dvWuM3GN+lUVu7F2jRRdvrkuQvhE+atg2xnhdAnbE8fAto+gDgflE3uC9CB1YarkXbW0PSr2FSPO23HCRMJu/VwYTQjof9dHwQDGfGaVxJXtCMBGbcaZ60K3+3xMSvKAt9Ok6SvxBeeV/D7otc9TrWZGk0JZHVS/pguMTv+bOCYE/8IMlfCD95PttvyQkwDdekBngYBIx7tg+tY5rH1+Qvc/5C+KilJ8FcIHfbNtKuXAzGanW5FhDofYRakjR8GRhbF0n+QhhMLni8GGzUs31PXKd6WidJ/kIYUC7UDgBYybZa5YYtg5Hkj741fI0aOxji60nPWrKJA7uT+sDthEWEU1pRycVVf6GLRtc04np0YMTksUTERFFRUsbnaz+h8Ph5FSMGT3x9aid7Z/jkr2cNX6PGDob4etKzlmziwO7c/NgETFc29A9tE0bEYxP44cV3+HT/CVVjx/XowE+fmERIqKOGVGT7aH76xCT+uXidJgm4ofioHF+f2skNM3wlLz1r+Bo1djDE15OetWRTH7jdmfhrmEwmYh+4XfXYIyaPdSbeGiGhIYyYPFb12HrH1752cuMMn/z1rOFr1NjBEL9h6i531LOWbFhEuJf2gBfxdRMRE+WlPdJje2uKr13tZN8ZPvnrWcPXqLGDIb5nE9FinbuetWRtFZVe2gNaxNejipIyL+3lqsfWO742tZObxvDJ/+VNjpq9NYlIyxq+Ro0dDPHdOZL+li0DyZ6XTeq8VNVWvhzc9CW28sraAUDDWrJbV/2F+vd1KorC1lV/UT3252s/wV5ld2mzV9n5fO0nqsfWO/60NZ6/6QamdnLzBOQO371797J69WrsdjsZGRmMGzfO5fnc3FzWrVtHfHw8AGPGjCEjI6Pxzml0h2/NqhM9avgaNXYwxK+l/V2tztU+OtSyrV3tE4atwsbWVX/hjMoXe2vUrraJpKKkXMfVPq7x01B/SwetVvtotr2D3W7n0UcfZd68eVgsFubOncujjz5K165dncfk5uZy9OhRHnjggSa9tmzvINRl7LtaRa00WvZ+PnVptr3DkSNHSExMpFOnTgCMGDGCnTt3uiR/IYKPsfewEcLv5F9QUIDFYnE+tlgsHD582O24HTt28PXXX9O5c2emTJlCQkKC2zFZWVlkZWUBsGjRIn+7JoQXkviF8Dv5e5o1qr+OeMiQIdx4442EhYWxceNGli1bxvz5891+LjMzk8zMTH+7JIQQohF+r/axWCxcuHDB+fjChQvExcW5HNO2bVvCwhwLWjMzM/n222/9DSuEEMIPfif/3r17c/r0ac6dO0dVVRWff/45ycnJLscUFhY6/71r1y65HiCEEDrze9rHbDZz//33s2DBAux2O+np6XTr1o333nuP3r17k5yczD//+U927dqF2WwmJiaGGTNmBKLvQgghmikgG7sNHjyYwYMHu7Tdfffdzn9PnDiRiRMnBiKUEEKIADD8Hb5CCGFEkvyFEMKAJPkLIYQBSfIXQggDkuQvhBAGJMlfCCEMyPA1fMG4hcSv7QGvToYOMXC+BB5aC3uPaxc/2mKh78hUwiMiqKyoIG/LVkrr3C2upvReO7j+yD+oMtmxTU6lOCwcsjdrEltvehYxj+jbl+H3jyc60kxpeTXb3/iQirw8TWJDna2028dQVlSi6VbaL0+AX9cpU/rKJnj0HU1CexSQ/fzVosWWzvULidcUFWnthcSv7QHZT0B4neG/sgpGLdZmAIi2WLju9tsICan98mm329nzl7+qPABM5LcPlPL0TX91KaalAH9bt4OCVj4A1C9iDo6CJloUUY/o25ef/e8vCA1RcFSyUaiym/jbkg80GQAi20cz8lfjausnXymis2XFx5QXlbps6wzU29rZv22dX54AD9/s3v6HjYEfAHzd0tnw0z5GLST+6mTXxA+Ox69O1iZ+35GpLokfICQkhL4jU1WKOJH09IVs2TKQx0f8w1MVRUZPGK5S7OChZxHz4fePr5P4AUyEhigMv3+86rEB+o8eWpv4ARQIiwyn/+ihAOQCq7dt41hGBlitpFZlY7VCevpAHCU+m+/XXvKJt3YtGD75B3chcfV0iPHcnuClPdDCIyI8tod5afeP6xbOYaZqz7FDgvZLcMDoWcQ8OtKMp+LFjnb1RbWPqU38NRSIio12acoFjm3b5jYApKcvxN9BIJgYPvkHZyFx9Z0v8dye76U90CorKjy227y0N4/jbL/+3v226voJ6Epsu+f21kTPIual5dV4yr6OdvWVFZV4Gnsou+g+559L7beA1HmpZM8L3LeAYGH45B98hcS18dBaxxx/XZVVjnYt5G3Zit1er5i23U7elq0BilB7tl9TkP1YRgbHtm1j4zvbPZ0Asumd7QGKHbz0LGK+/Y0PqbI75vodHHP+29/4UPXYAAc3fYmtvLLurBO28koObvrS68/k4vlbgGMA8H0QeMVLPvHWrgXDX/CFYCokrq2a1T4JMY4zfr1W+4RFRGAL2Gofx/+QjVXqih+VwegJwwkLUbDZTWx6Z3urv9hbQ88i6kGz2ic2mrKLpT6v9knjysVg8FDn17eLwVqt9tGsgLuapIC7aBr38oyAlGgUAZGGtyLvwVXgXbMC7kIEB6nLK0RTSPIXLVxt0gdJ/EL4SpK/aMHkbF+I5pLkL1qgiVdWXCCJX4hmkuQvWph6Z/vzHEkfkMQvRBMYfp2/aEm8T/Pk6tsxYRDe1/y3PHLmL1qAekm/CpnmEZrLrfnHtm30tFpJtYLVOgoYSE6OrwNA8CwLlXX+IsjJRV0RfNJw3wHUF1rcG6DpTV579+5l9erV2O12MjIyGDdunMvzNpuNV155hW+//Za2bdsyc+ZMOnbs2HjnJPkbmCzhFMEvDddBoDFa3Bym2U1edrudVatWMW/ePCwWC3PnziU5OZmuXbs6j8nOziY6Opo//OEP/Otf/+Ltt9/mscce8ze0aLXkbF+0DLngnAbyheepIn2mgvxO/keOHCExMZFOnToBMGLECHbu3OmS/Hft2sUvfvELAIYPH84bb7yBoiiY6m+nKQzOt315hAgmuUDulRVnDUkDx7UCrGRbrWy11nwLmIgeA4Dfq30KCgqwWCzOxxaLhYKCAq/HmM1moqKiuHTpkttrZWVlMWfOHObMmeNvt0SLI4lftG65XNkmOkhWDPl95u/pkkH9M3pfjgHIzMwkMzPT3y41WfukJK7OGEVoWBhVNhtfb86m6NQpTWLrWT94XEp7Vv7yMlGhVZRVhTLt7TZ8vE277UzDo6LoOugntImK4nJZG77fV6lZbOXOh7lnTHvCQuzY7CG8u6EI05/+oF38zj3odtdEottFUFpcwcn312M6rc2WqnrWsS2N6sg3gx6gPKoDkWXn6bdvFdFl5zSJrbcew/py09RbMYeFUm2rwrxmKalTHdNAVutArNaFV64F+ML/bwp+J3+LxcKFOtvwXrhwgbi4OI/HWCwWqqurKSsrIyZGo5JRjWiflMQ1t4x1Dkbm0FCuuWUsX/3jE9UHgPr1gwckwdBe2tQPHpfSng/uKybE5BiYI81VfHDfZX5Be01FjUGmAAAStUlEQVQGgPCoKPpnZmAOCwMgKi6Udh3NUFaF2iuQlTsfZuotbTHhKCISaq5m6i1tWcPDmgwASuceDJs1jYiwKyUNLdF0mTWNHb9fqfoAUL+ObfukBDr06uKsY6um0qiO/CtzKZVhMZhQKIrrw4WO13Bj1iOtfgDoMawvab+6o/ak1xyOPf1qzj01g9TwjmC1Oq8F+CIQU0V+/1/Wu3dvTp8+zblz54iPj+fzzz/nkUcecTlmyJAh5Obm0qdPH7Zv386AAQOCZr7/6oxRbn0xmUxcnTGKL9auUzV2Q/WD53ygamhW/vKyM/HXCDEprPzlZT5ufPrSb10H/cSZ+GuYw0wQfwmI8/xDAXLPmPbOxF/DdKX9vT+pGhqAbndNrE38V6JHhCl0u2si37/8gqqxG6pj++8PclSN/c2gB5yJH8CEQmVYDN8MeoAh29V933q7aeqtHvNM/NRbOfbQEud9A9nzGn8tx7LSgX4PAH4nf7PZzP3338+CBQuw2+2kp6fTrVs33nvvPXr37k1ycjKjRo3ilVde4eGHHyYmJoaZM2f6GzZgQusloBr1E5Ma9KwfHBVa1aT2QGsT5bmWLKHql/QLC7E3qT3QottF4LGWbTs16he78rWOrRrKozo4E38NEwoVUR1Uj603c5jnVGsOC3WuGCIjo7ZgTANqBgnHBeOFzV42GpDv14MHD2bw4MEubXfffbfz3+Hh4cyaNSsQoQKuymbDHOr+MVTbbKrHPl3kmOqpOwBoVT+4rCqUSLN7oi+rCgXUf++Xy8qIivNwhl+lfjFvmz2EULP7IGOza7PbSWlxBViicR0AFEe7ysqKSmiflOA6AHipYxtokWXnKYrr4zIAKJiIKNOmipieqm1VhJjDPbaD693DjboySLgvG23aAGD4vX2+3pztdkFaURS+3pytemw96wdPe7sNdsX17NOumJj2dhv1gwPf7/uP2wBbbVOgoK3qsd/dUOSxhu+7G7S52H3y/fVU2Fxr2VbYTJx8X/3lfs2pYxso/fatItxWgnIluIKJcFsJ/fatUj223j5b83ePeeazNX93acv18U/9FUNbtgwkPX0hTVk1ZLZafbw7QQe/+Y36NVUrLl3i4pmzxHXrBiYTtsuX2f/pRk1W+5RUwMYD0LEtlFfCvpPwxPvarPb55kQF/ymIJbO/yTHo2MKZvDZas9U+1TYbBSe/JzwqEnt1NaUF7Tj6xWW6d0kkLQ162I9Bbi5FJ07wXYBjmw5+yd6wa+nXOwqTCS7bzbz1z2LNVvuYSi7y/f6j2JP6UWkP4dzZcg6+vkaT1T5VFTZOHfiWiLbRVFfaKDh5nl3vb9ZktU+4rZTEk1u5HJVAaHUFcQXfMPiLha3+Yi/AxVMXKDpznq4De2MymaiqtLF11V85vqN59Yu/A/aeOEH7tWu59mg2PVJ70HNUT44f78iUKb69huztI4KErPMXojnScK0tnJrq288ZftpHCCFaslzqTAPN8zHzI1s6CyFEi5eLY4uJNKCnjz8jZ/5CCNFK5DbhWEn+QghhQJL8hRDCgCT5iyCxHlhPTs5+rNYrt7BbrfRMSSFN554J0RpJ8hdBxnUA2Pr8Vnpu3sx9MggIEVCyzl8EManoJURT3edjSpczfxHEPE8DybcAIfwnZ/6iBZC7f4XwlZz5i1ZELgYLEWiS/EWLJAOAEP6R7R2AaIuFviNTCY+IoLKigrwtWymtU5pSTa51bMv4ft9/qCwr0yR210GD6D18mGMvaUXh6PYdfL9vnyaxQd/aySeGTKbvHWOIb1NBweUI8j7aQPd/r9Uktt70rOFrZMH2uRs++UdbLFx3+22EhDi+BIVHRXHd7bex5y9/VX0AcK9jG0e7jh05mLVZ9QGg66BBXDXihtoGk8n5WIsBQM/aySeGTOb2ydcTZT6NgokfRSr0m3w9f4FWPwDoWcPXyILxczf8tE/fkanOxF8jJCSEviN93x2vuTzXsQ2j66CfqB679/BhTWoPtIZqJ6ut7x1jiDJXuhQViTJX0veOMarH1ltDNXyFeoLxczd88g+P8Fw3NcxLeyB5q2Mb7q2+bSCZ6teQbaQ9wPSsnRzfpsKZ+GsomIgLV7+Mot70rOFrZMH4uRs++VdWeP4f3ualPZAue5na0WTO39tyMI1W/lZ5qZGsRe3kgssRHguJF1aqP+DrrayoxFPteE1q+BpZMH7uhk/+eVu2YrfbXdrsdjt5W7aqHttzHVsb3+/7j+qxj27f0aT2QGte7eTa5Z71pTUhdt5HGyirDncOACYUyqrDyftoQxNepWXSs4avkQXj5y43eVG72icsIgKbTqt9wqOiqDToah9zWBjVTVrt4/9NXzWrfeLCKyisNOhqn9hoyi6W6r7qxCi0+tx9vcnLr+RfUlLCiy++yPnz5+nQoQOPPfYYMTExbsfdfffddO/eHYCEhASefPJJ3zond/iKBsneP0LUp0nyf+utt4iJiWHcuHF8/PHHlJSUcO+997odN2nSJNatW9fk15fkLxpXOwCADAJCaLK9w86dOxk5ciQAI0eOZOfOnf68nBDNsJ6cnKcYOVK2fhCiKfy6yevixYvExcUBEBcXR3FxscfjbDYbc+bMwWw2c/vttzN0qOe1rVlZWWRlZQGwaNEif7omDGc9OTkTgYFYraNItUJPq5WeIN8ChPCg0eT/3HPPUVRU5NZ+zz33+Bxk+fLlxMfHc/bsWX7729/SvXt3EhMT3Y7LzMwkMzPT59cVwpX7AFDzLQAZAIRw0Wjyf+aZZ7w+FxsbS2FhIXFxcRQWFtKuXTuPx8XHxwPQqVMn+vfvz3fffecx+QshhNCGX3P+ycnJbNmyBYAtW7Zw/fXXux1TUlKC7cpa9uLiYvLy8ujatas/YYUQQvjJrzn/cePG8eKLL5KdnU1CQgKzZs0C4OjRo2zatInp06dz6tQpVq5cSUhICHa7nXHjxknyF0IInfmV/Nu2bcuzzz7r1t67d2969+4NQN++fVmyZIk/YYQQQgSY4bd3EEIII5LkL1o3TxsBCSFkbx/RWsnWD8KYpIC7MDjPBd/vkzt/hQDkzF+0ev7vACpES6LJxm5q0yr5D5symYg6lbsqKirY8aY22/sOu/eXRETXVvOpKC1lx1tvaxNbx/cNMGziBCLatq2Nf+kSO9a/o1I012mgUWs7QkSdHWgrLjLpzWtViu1uf7972ZsyHyXEjMlezbXbfsPAb97SLL5R6VlEXavYkvx9NGzKZCIjI93ay8vLVU+Ew+79JZEetsAuLylRfQDQ832DI/FHergjvLy4WPUBgH4nrjxWXEvrlRdpMgDs73cve9Ked2u/LneeDAAqql9EvaagihZF1LWMLXP+PorwUqvXW3tAY0d7rt/prT2gsXV834DLGb8v7YHhuA6A3cvTEbEqxq61N2V+k9pFYOhZRD0YC7j7dZOXEC3HlbN+gJATuJ31a0gJMTepXQSGnkXUpYC7ELqone/PnpcNdrtuiR/AZK9uUrsIDD2LqEsB9yBUUVHRpPaAxi71/B/eW3tAY+v4vsFxcbcp7c0zEU/r/am46KVTXtoD7Nptv2lSuwgMPYuoSwH3JpLVPirHbtWrfTwkfWoLu6ybstd1jl9W+xiCnsXrW1UBd7XJOn/RPHJ3rzAuX5O/XPAVrYgUcxfCV5L8RSshZ/tCNIUkf9HCyfYNQjSHJH/RgtU725/nSPqAJH4hGiHJX7RQMs0jhD8k+YsWpl7Sr0ISvxDNIMlftCByti9EoEjyFy1A7b48kviFCAxJ/iLIeb6om6t3t4Ro4fxK/l988QUffPABp06dYuHChfTu3dvjcXv37mX16tXY7XYyMjIYN26cP2GFIcgSTiHU5Ffy79atG48//jgrV670eozdbmfVqlXMmzcPi8XC3LlzSU5OpmvXrv6EFq2a+9k+IIlfiADyK/n7ksCPHDlCYmIinTp1AmDEiBHs3LlTkr/wQi7qCqEF1bd0LigowGKxOB9bLBYKCgrUDitaJEn8Qmil0TP/5557jqKiIrf2e+65h+uvv77RAJ42DTWZ6lc1cMjKyiIrKwuARYsWoSgLG3190VqNglGj6An01LsrQrRGSgDMnz9fOXLkiMfn8vLylOeff975+MMPP1Q+/PDDZsV58sknm/VzepH+qkv6qy7pr7r07q/q0z69e/fm9OnTnDt3jqqqKj7//HOSk5PVDiuEEKIBfiX/L7/8kunTp3Po0CEWLVrEggULAMc8/wsvvACA2Wzm/vvvZ8GCBTz22GPccMMNdOvWzf+eCyGEaDa/VvsMHTqUoUOHurXHx8czd+5c5+PBgwczePBgf0IBkJmZ6fdraEn6qy7pr7qkv+rSu79BXcZRCCGEOlSf8xdCCBF8JPkLIYQBBfXGbr7uHfQ///M/REREEBISgtlsZtGiRRr31KGl7XVUUlLCiy++yPnz5+nQoQOPPfYYMTExbsfdfffddO/eHYCEhASefPJJTfvZ2Odls9l45ZVX+Pbbb2nbti0zZ86kY8eOmvaxrsb6m5uby7p164iPjwdgzJgxZGRk6NFVli9fzu7du4mNjWXJkiVuzyuKwurVq9mzZw9t2rRhxowZ9OrVS4eeOjTW3wMHDrB48WLnf/9hw4Zx5513at1Np/z8fJYtW0ZRUREmk4nMzEzGjh3rcoxun7GuC00bcfLkSeXUqVMN3kegKIoyY8YM5eLFixr2zDNf+ltdXa38+te/Vs6cOaPYbDbl8ccfV06ePKlxTx3WrVunfPTRR4qiKMpHH32krFu3zuNx9957r5bdcuHL57VhwwZlxYoViqIoymeffab8/ve/16OriqL41t+cnBzl9ddf16mHrg4cOKAcPXpUmTVrlsfn//3vfysLFixQ7Ha7kpeXp8ydO1fjHrpqrL/79+9XXnjhBY175V1BQYFy9OhRRVEUpaysTHnkkUfcfh/0+oyDetqna9eudOnSRe9u+MyX/tbd6yg0NNS515Eedu7cyciRIwEYOXKkbv1oiC+f165du0hLSwNg+PDh7N+/3+Od5VoIpv++vujfv7/Hb3s1du3aRWpqKiaTiT59+lBaWkphYaGGPXTVWH+DTVxcnPMsPjIykqSkJLftbfT6jIN62qcpau4xGD16tO5LqBriaa+jw4cP69KXixcvEhcXBzh+SYuLiz0eZ7PZmDNnDmazmdtvv93j8l61+PJ51T3GbDYTFRXFpUuXaNeunWb99NQX8P7fd8eOHXz99dd07tyZKVOmkJCQoGU3fVZQUODSt5q9uWp+b4LRoUOHmD17NnFxcUyaNClo7is6d+4cx44d46qrrnJp1+sz1j35+7t3UM1rxMfHc/HiRZ5//nm6dOlC//79A91VZyyt9joKhIb666vly5cTHx/P2bNn+e1vf0v37t1JTEwMZDe98uXz0vozbYgvfRkyZAg33ngjYWFhbNy4kWXLljF//nytutgkwfTZ+qJnz54sX76ciIgIdu/eze9+9zuWLl2qd7eoqKhgyZIlTJ06laioKJfn9PqMdU/+zzzzjN+vUXPhLDY2luuvv54jR46olvz97a/FYuHChQvOxxcuXFB1hG+ov7GxsRQWFhIXF0dhYaHXM+Waz7dTp07079+f7777TrPk78vnVXOMxWKhurqasrIy3aYGfOlv27Ztnf/OzMzk7bff1qx/TWWxWMjPz3c+Vvv31V91E+vgwYNZtWoVxcXFunwLrFFVVcWSJUtISUlh2LBhbs/r9RkH9Zy/LyoqKigvL3f+e9++fc6VKcEomPY6Sk5OZsuWLQBs2bLF4zeXkpISbDYbAMXFxeTl5Wlai8GXz2vIkCHk5uYCsH37dgYMGKDb2akv/a07n7tr166grm2RnJzM1q1bURSFQ4cOERUVFdTJv6ioyHkmfeTIEex2u8tgqzVFUXjttddISkri1ltv9XiMXp9xUN/h++WXX/LGG29QXFxMdHQ0P/rRj3j66acpKChgxYoVzJ07l7Nnz/J///d/AFRXV3PTTTcxfvz4oO0vwO7du3nzzTex2+2kp6fr1t9Lly7x4osvkp+fT0JCArNmzSImJoajR4+yadMmpk+fTl5eHitXriQkJAS73c4tt9zCqFGjNO2np8/rvffeo3fv3iQnJ1NZWckrr7zCsWPHiImJYebMmc7iQXporL/r169n165dmM1mYmJiePDBB0lKStKlry+99BIHDx7k0qVLxMbGctddd1FVVQXAzTffjKIorFq1iq+++orw8HBmzJjhdQlzMPR3w4YNbNy4EbPZTHh4OJMnT6Zv37669febb77h2WefpXv37s4TkgkTJjjP9PX8jIM6+QshhFBHi5/2EUII0XSS/IUQwoAk+QshhAFJ8hdCCAOS5C+EEAYkyV8IIQxIkr8QQhjQ/wdUsJseVE9I3QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x79e2ad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotDecisionBoundary(knn, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "58px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
